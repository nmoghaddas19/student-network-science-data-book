{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc082d74-4596-4e0e-abba-86789f6d208c",
   "metadata": {},
   "source": [
    "# Graph Similarity Measures\n",
    "\n",
    "Goal of today's class:\n",
    "\n",
    "1. Understand the basic concept of graph similarity and the difference between descriptors and metrics\n",
    "2. Implement a few similarity measures\n",
    "3. Understand that different measures give us different information and may be appropriate in different settings\n",
    "4. Appreciate some of the main problems that graph distances can help to address\n",
    "\n",
    "This lesson draws on [Tantardini et al., 2019](https://doi.org/10.1038/s41598-019-53708-y), [Wills & Meyer, 2020](https://doi.org/10.1371/journal.pone.0228728) and [Hartle et al., 2020](https://doi.org/10.1098/rspa.2019.0744) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88316dd7-4fcf-49f6-bd28-fff4200bad0f",
   "metadata": {},
   "source": [
    "## What is graph distance?\n",
    "\n",
    "Graphs are complex, high dimensional objects. However sometimes we just want to ask something like: '_How similar are these two graphs?_'. Graph distances refer to a host of methods which attempt to answer this question by devising some function which takes two graphs as inputs and returns a single number representing how dissimilar they are. Such functions tend to have two components:\n",
    "1. A **descriptor**: the descriptor extracts some property or properties of the graph that we believe to be important\n",
    "2. A **metric**: the metric compares the descriptors of both graphs giving a distance\n",
    "\n",
    "In other words, given $G_1$ and $G_2$, we seek a descriptor $Q$ and a metric $D$ such that \n",
    "\n",
    "$$D(Q(G_1), Q(G_2)) = d$$ \n",
    "\n",
    "where d is the distance between the two graphs. The best way to do this is not straightforward because graphs are multidimensional objects which have lots of properties and it is not clear which properties are most 'important' or with which metric they should be compared. As a result, many, many graph distance measures have been proposed. \n",
    "\n",
    "\n",
    "<!-- \n",
    "There are two broad categories of problems when it comes to comparing graphs. Firstly, we may want to compare graphs where the each node in $G_1$ maps on to a node in $G_2$ (**Known Node Correspondence**). For example we may be interested in different types of social interaction that occur between the same set of people, or how the flight patterns between the same set of airports changes over time or between different airlines. Secondly, we may be interested in comparing graphs where there isn't a precise mapping of nodes between the two graphs (**Unknown Node Correspondence**). For example if we wanted to know how similar are the commuting patterns between Boston and San Diego, or how the interaction structure of different protein complexes compares. Or we may be interested in comparing graphs of different sizes. There are different measures for tackling each of these problems. In general, measures for comparing graphs of unknown node correspondence can also be used for graphs with known node correspondence but not vice versa.\n",
    "\n",
    "Distance measures also differ in the types of graph they work on. Not all measures will work on directed or weighted graphs. -->\n",
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13293fd0-5fa3-4b43-9ca3-c38cfba402fa",
   "metadata": {},
   "source": [
    "## Why do we care?\n",
    "1. Temporal anomaly detection:\n",
    "3. Graph classification and clustering:\n",
    "4. Similar nodes:\n",
    "5. Within ensemble graph distance:\n",
    "6. Between ensemble graph distance:\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf2fd9-0692-4ac2-972f-40611c2c86f1",
   "metadata": {},
   "source": [
    "## Some commonly used descriptors\n",
    "\n",
    " 1. Adjacency matrix\n",
    "\n",
    " 3. Degree distribution\n",
    "\n",
    " 5. Node affinity matrix (Fast Belief Propagation)\n",
    " \n",
    " 6. Eigenvalue decomposition\n",
    "\n",
    " 8. Network portrait\n",
    "\n",
    " 10. Communicability sequence  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd13748-94e2-43e8-985e-4703844c33e6",
   "metadata": {},
   "source": [
    "## Some commonly used metrics\n",
    "\n",
    "1. Euclidian distance\n",
    "\n",
    "2. Matusita distance\n",
    "\n",
    "3. Jensen-Shannon divergence\n",
    "\n",
    "4. Jaccard distance\n",
    "\n",
    "5. Hamming distance\n",
    "\n",
    "6. Canberra distance\n",
    "\n",
    "Brief note about how you could theoretically pair any descriptor with any metric.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5072f6ef-5d54-4081-ade8-6ba34f4fe5f6",
   "metadata": {},
   "source": [
    "## Distance measure 1: Frobenius distance (adjacency matrix + Euclidian distance)\n",
    "\n",
    "$$ \\sqrt{\\sum_{i,j} \\lvert A_{ij}^1 - A_{ij}^2 \\rvert ^2 }$$\n",
    "- Intuition\n",
    "- Intro netrd \n",
    "- Quick demo (test some properties we might expect a distance measure to have eg. symmetry, identity, perturbation test)\n",
    "\n",
    "<img src=\"figs/perturbation.png\" alt=\"Perturbation\" width=\"400\"/>\n",
    "(Tantardini et al., 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5656a2-cd98-4578-8749-77cde2bf9192",
   "metadata": {},
   "source": [
    "## Distance measure 2: DeltaCon (node affinity + Matusita distance)\n",
    "$$s_{ij} = [I - \\epsilon^2 D - \\epsilon A]^{-1}$$\n",
    "$$ d = \\sqrt{\\sum_{i=1}^N \\sum_{j=1}^N \\sqrt{s_{ij}^1} - \\sqrt{s_{ij}^2}}$$\n",
    "- Intuition\n",
    "- Demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a58aac-109e-4a7d-8443-2e13e52a461a",
   "metadata": {},
   "source": [
    "## Distance measure 3: Adjacency spectral distance?\n",
    "$$ d = \\sqrt{\\sum_{i=1}^n (\\lambda_i^A - \\lambda_i^{A'})^2}$$\n",
    "- Intuition\n",
    "- Intro NetComp\n",
    "- Demo\n",
    "- Explore how different eigenvalues tell us about different levels of structure in the graph\n",
    "\n",
    "\n",
    "<img src=\"figs/spectral.png\" alt=\"Spectral\" width=\"600\"/>\n",
    "(Wills & Meyer 2020)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb49899-ec46-42c0-9caa-adf5af8b0326",
   "metadata": {},
   "source": [
    "## Problem 1: Graph classification\n",
    "- Data: brain graphs with metadata/ or synthetic data generated from different graph ensembles\n",
    "- How well does each distance measure identify the group the graph came from?\n",
    "\n",
    "<img src=\"figs/classification.png\" alt=\"Classification\" width=\"600\"/>\n",
    "(Tantardini et al., 2019)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d991567-3894-4526-8b29-233acb30e3c7",
   "metadata": {},
   "source": [
    "## Problem 2: Anomaly detection\n",
    "- Data: longitudinal mobility data?/ any temporal network\n",
    "- How well does each distance measure identify anomalies eg snowstorms, lockdowns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a60020-50d7-40c0-ae89-01c9576b6a9d",
   "metadata": {},
   "source": [
    "## Problem 3: Within ensemble graph distance and desirable distance properties\n",
    "- Data: synthetic data\n",
    "- Discuss properties we might expect a distance measure to have for different ensembles (eg for ER: collapse to 0 at p=0 or 1, max at p=0.5, symmetric)\n",
    "\n",
    "<img src=\"figs/wegd.png\" alt=\"wegd\" width=\"400\"/>\n",
    "(Hartle et al., 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121bdbb6-c2f4-4522-ae76-c441f1341c89",
   "metadata": {},
   "source": [
    "## If there's time: graphlet based methods\n",
    "\n",
    "<img src=\"figs/graphlets.png\" alt=\"graphlets\" width=\"600\"/>\n",
    "(Tantardini et al., 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bfb469-4062-4ab8-ae7c-aca8cf72697d",
   "metadata": {},
   "source": [
    "## If there's time: Time machine: Graph isomorphism and exact graph matching\n",
    "- Explain isomorphism with pictures\n",
    "- Touch on early examples of exact graph matching (eg. graph edit distance, maximum common subgraph)\n",
    "- Discuss computational challenges of exact graph matching and the move towards inexact graph matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ad0e8-41c9-4c09-bb32-647db7767439",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "## References and further resources:\n",
    "\n",
    "1. Hartle, H., Klein, B., McCabe, S., Daniels, A., St-Onge, G., Murphy, C., Hébert-Dufresne, L., 2020. Network comparison and the within-ensemble graph distance. Proc. R. Soc. A. 476, 20190744. https://doi.org/10.1098/rspa.2019.0744\n",
    "2. Soundarajan, S., Eliassi-Rad, T., Gallagher, B., 2014. A Guide to Selecting a Network Similarity Method, in: Proceedings of the 2014 SIAM International Conference on Data Mining. Presented at the Proceedings of the 2014 SIAM International Conference on Data Mining, Society for Industrial and Applied Mathematics, pp. 1037–1045. https://doi.org/10.1137/1.9781611973440.118\n",
    "3. Tantardini, M., Ieva, F., Tajoli, L., Piccardi, C., 2019. Comparing methods for comparing networks. Sci Rep 9, 17557. https://doi.org/10.1038/s41598-019-53708-y\n",
    "4. Wills, P., Meyer, F.G., 2020. Metrics for graph comparison: A practitioner’s guide. PLoS ONE 15, e0228728. https://doi.org/10.1371/journal.pone.0228728\n",
    "5. Koutra, D., Vogelstein, J.T., Faloutsos, C., 2013. DeltaCon : A Principled Massive-Graph Similarity Function, in: Proceedings of the 2013 SIAM International Conference on Data Mining. Presented at the Proceedings of the 2013 SIAM International Conference on Data Mining, Society for Industrial and Applied Mathematics, pp. 162–170. https://doi.org/10.1137/1.9781611972832.18\n",
    "6. Koutra, D., Shah, N., Vogelstein, J.T., Gallagher, B., Faloutsos, C., 2016. D elta C on: Principled Massive-Graph Similarity Function with Attribution. ACM Trans. Knowl. Discov. Data 10, 1–43. https://doi.org/10.1145/2824443\n",
    "7. McCabe, S., Torres, L., LaRock, T., Haque, S., Yang, C.-H., Hartle, H., Klein, B., 2021. netrd: A library for network reconstruction and graph distances. JOSS 6, 2990. https://doi.org/10.21105/joss.02990\n",
    "8. [netrd package](https://github.com/netsiphd/netrd/)\n",
    "9. [NetComp package](https://github.com/peterewills/NetComp/tree/master)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef1ae41-84be-4eed-9632-84697403c5df",
   "metadata": {},
   "source": [
    "<!-- There are lots and lots of graph distance measures. Here are a few:\n",
    "1. **Known node correspondence**\n",
    "    1. Matrix differences\n",
    "       1. Frobenius\n",
    "       2. Jaccard\n",
    "       3. Hamming\n",
    "       4. Canberra\n",
    "       5. Resistance perturbation?\n",
    "    3. DeltaCon [5](https://doi.org/10.1137/1.9781611972832.18) [6](https://doi.org/10.1145/2824443)\n",
    "    4. Cut distance\n",
    "2. **Unknown node correspondence**\n",
    "   1. Spectral distances\n",
    "   2. Global statistics\n",
    "   3. Mesoscopic response functions\n",
    "   4. Graphlet based methods\n",
    "   5. Alignment based methods\n",
    "   6. Portrait divergence\n",
    "   7. Graph kernels\n",
    "   8. Persistent homology\n",
    "   9. Bayesian methods\n",
    "   10. Jensen-Shannon divergence\n",
    "   11. Entropy divergence\n",
    "   12. NetSimile -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ea385-7518-4a82-af49-be0f9020d58d",
   "metadata": {},
   "source": [
    "## 1. Frobenius norm\n",
    "- Idea that distances should have the property that isomorphic (or minimally edited graphs) ought to have a smaller distance\n",
    "- Compute $d$ for various instances of ER graph with different densities\n",
    "- Test sensitivity to removing, adding, switching or randomizing edges\n",
    "    - We expect distance to start at 0, and be a monotonically increasing function of perturbation. For randomization, distance should saturate as graph is fully randomized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1027a3-7292-495c-bd2e-bc6ab9e907ec",
   "metadata": {},
   "source": [
    "### What properties might a distance measure have?\n",
    "We can probably think of some properties that we might like a hypothetical distance measure to have. These are all arguable to some extent, but some such properties are\n",
    "1. **Sensitivity to perturbation**: If we perturb a graph $G$ slightly (eg adding/removing edges) resulting in $G'$ we might expect $D(G, G')$ to start off close to 0 and grow as the perturbation increases.\n",
    "\n",
    "2. **Irrelevance of random differences**: If we perturb a graph $G$ by randomizing edges resulting in $G'$, we might expect the distance $D(G, G')$ to asymptote as the graph becomes fully randomized.\n",
    "\n",
    "3. **Identity property**: the distance between the same graph (or two isomorphic graphs) should be 0 ie. $D(G_1, G_1) = 0$. Similarly, if $D(G_1,G_2) = 0$ then we might expect that $G_1 = G_2$.\n",
    "\n",
    "4. **Symmetry property**: we might expect that $D(G_1, G_2) = D(G_2, G_1)$\n",
    "\n",
    "5. **Zero property**: given $G$ and $\\overline{G}$ where $\\overline{G}$ contains all the edges which $G$ does not contain, we might expect that $D(G,\\overline{G})$ is maximal.\n",
    "\n",
    "6. **Within vs between family property**: We might expect that the average distance between graphs from different families should be greater than the distance between graphs of the same family. In other words, given two graphs that were generated from generative models $G(\\theta)$ and $F(\\omega)$ respectively, we expect that on average $D(G(\\theta), F(\\omega))$ should be greater than $D(G(\\theta), G(\\theta))$ or $D(F(\\omega), F(\\omega))$ for randomly drawn samples of $\\theta$ and $\\omega$. \n",
    "\n",
    "7. **The triangle inequality**: If we have three graphs $G_1$, $G_2$, $G_3$, we might expect that $D(G_1, G_3) \\leq D(G_1, G_2) + D(G_2, G_3)$. \n",
    "\n",
    "Any more? What do you think a good distance measure should do?\n",
    "\n",
    "Which of these seem most important to you when comparing graphs? Are there any that don't seem so important?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf1083-3ccc-41b5-8072-1cbef2fe4762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frobenius_norm_distance(g1, g2):\n",
    "    \"\"\"\n",
    "    Calculate the Frobenius distance between two graphs, g1 and g2.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c7ec7d-1f2a-48ae-8710-a5b7be050b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_graph(g, distance_function):\n",
    "    \"\"\"\n",
    "    Iteratively perturb graph g and compute distance between g and the perturbed graph at each step \n",
    "    using the distance measure distance_function. Two different perturbations are considered:\n",
    "    1. Removing edges\n",
    "    2. Adding edges\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3384f36-4100-4629-9111-bcb881e271c0",
   "metadata": {},
   "source": [
    "Is the Frobenius distance symmetric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf51a46-1afe-4ad1-a5f3-70a6b22ff519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "g1 = nx.watts_strogatz_graph(500, 9, 0.05)\n",
    "g2 = nx.watts_strogatz_graph(500, 9, 0.01)\n",
    "d = frobenius_norm_distance(g1, g2) \n",
    "print('$D(G_1, G_2) =$', d)\n",
    "d = frobenius_norm_distance(g2, g1) \n",
    "print('$D(G_2, G_1) =$', d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b97d07-4727-4a89-9706-6db149f7c48c",
   "metadata": {},
   "source": [
    "Does Frobenius distance obey the identity property?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d59743-a058-436f-91e8-e5d51fbc10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = nx.watts_strogatz_graph(500, 9, 0.05)\n",
    "g2 = g1.copy()\n",
    "d = frobenius_norm_distance(g1, g2) \n",
    "print('$D(G_1, G_1) =$', d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31ba41-135a-4fef-b390-8e5db03f47dc",
   "metadata": {},
   "source": [
    "Lets test the sensitivity to perturbation property for this distance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b574b9b-75aa-4171-b622-7ba18ee44a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Your turn!\n",
    "\n",
    "def perturb_graph():\n",
    "    # Write a function that takes as input a graph of your choice and randomly switches edges. \n",
    "    # Compute at each step the distance between the original and perturbed graphs and plot the results\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d634f4-67d0-483c-970d-72749b827313",
   "metadata": {},
   "source": [
    "## 2. DeltaCon \n",
    "\n",
    "### Why DeltaCon?\n",
    "- Matrix based measures such as Frobenius norm consider each edge equally. Removing 3 edges will have the same effect regardless of where in the graph they are removed from. DeltaCon measures graph similarity based on **node affinities** which are influenced by the structure of the graph. Therefore, adding or removing an edge which is more important structurally (eg. removing an edge which disconnects the graph) is given more importance in DeltaCon.\n",
    "- Robustness to noise: \n",
    "- Speed:\n",
    "\n",
    "### What is DeltaCon?\n",
    "$$s_{ij} = [I - \\epsilon^2 D - \\epsilon A]^{-1}$$\n",
    "$$ d = \\sqrt{\\sum_{i,j=1}^N \\sqrt{s_{ij}^1} - \\sqrt{s_{ij}^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85236711-7e96-4186-8c45-35a7eb6f8505",
   "metadata": {},
   "source": [
    "## 3. Spectral distances\n",
    "- \"Comparison using the first k eigenvalues  for small k allows one to focus on the community structure of the graph, while ignoring the local structure of the graph [15]. Inclusion of the highest-k eigenvalues  allows one to discern local features as well as global. This flexibility allows the user to target the particular scale at which she wishes to study the graph, and is a significant advantage of the spectral distances.\" (Wills 2020)\n",
    "- \"It is a well-known result that the multiplicity of the zero eigenvalue is the number of connected components of the graph, i.e. if , then there are precisely k connected components of the graph [22]. Furthermore, in such a case, the first k eigenvectors can be chosen to be the indicator functions of the components. There exists a relaxed version of this result: if the first k eigenvalues are very small (in a sense properly defined), then the graph can be strongly partitioned into k clusters (see [15] for the rigorous formulation of the result).\" (Wills 2020)\n",
    "- Maybe test using different numbers of eignevalues on different graphs to see the difference between macro and micro structure?\n",
    "\n",
    "$$ d = \\sqrt{\\sum_{i=1}^n (\\lambda_i^A - \\lambda_i^{A'})^2}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
