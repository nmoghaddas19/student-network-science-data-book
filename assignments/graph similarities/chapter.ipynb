{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc082d74-4596-4e0e-abba-86789f6d208c",
   "metadata": {},
   "source": [
    "# Graph Similarity Measures\n",
    "\n",
    "Goal of today's class:\n",
    "\n",
    "1. Understand the basic concept of graph similarity and graph isomorphism\n",
    "2. Implement and analyze different similarity measures\n",
    "3. Understand that different measures give us different information and may be appropriate in different settings\n",
    "\n",
    "This lesson draws heavily on [Tantardini et al., 2019](https://doi.org/10.1038/s41598-019-53708-y), [Wills & Meyer, 2020](https://doi.org/10.1371/journal.pone.0228728) and [Hartle et al., 2020](https://doi.org/10.1098/rspa.2019.0744)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e35db28-04d2-4258-893c-68b3984fdf60",
   "metadata": {},
   "source": [
    "### We want your final projects to showcase your ability to distill the following:\n",
    "1. Your understanding of a topic not covered in class\n",
    "2. Your accuracy in creating *correct* code around your topic, along with a strong reference list\n",
    "3. Your ability to convey your understanding via:\n",
    "    - A) Chunking the information into a single lesson that builds on itself (e.g. breaking down complex functions into parts, putting the pieces together, using different examples to illustrate your methods)\n",
    "    - B) Good examples / visuals / writeups of what results produced during the lesson / datasets used to illustrate your concept\n",
    "    - C) At least one interactive component (i.e., the \"Your Turn!\" in our lessons)\n",
    "\n",
    "Much like in our lessons, it's okay to include more than you imagine covering in a (hypothetical) 90 minute class period. Be sure to indicate what sections of your chapter are \"advanced topics\", and always include relevant citations or motivation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bfb469-4062-4ab8-ae7c-aca8cf72697d",
   "metadata": {},
   "source": [
    "## Graph isomorphism and exact graph matching\n",
    "- Explain isomorphism with pictures\n",
    "- Touch on early examples of exact graph matching (eg. graph edit distance, maximum common subgraph)\n",
    "- Discuss computational challenges of exact graph matching and the move towards inexact graph matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88316dd7-4fcf-49f6-bd28-fff4200bad0f",
   "metadata": {},
   "source": [
    "## What is graph distance?\n",
    "\n",
    "Graphs are complex, high dimensional objects. However sometimes we just want to ask something like: '_How similar are these two graphs?_'. Graph distances refer to a host of methods which attempt to answer this question by devising some function which takes two graphs as inputs and returns a single number representing how similar or different they are. In other words, given $G_1$ and $G_2$, we seek a function $D$ such that \n",
    "\n",
    "$$D(G_1, G_2) = d$$ \n",
    "\n",
    "where d is the distance between the two graphs. Of course, in the process of reducing a graph to a single number, information is going to be lost, no matter how ingenious your graph distance function is. Many, many graph distance measures have been proposed which each claim their own strangths.\n",
    "\n",
    "There are two broad categories of problems when it comes to comparing graphs. Firstly, we may want to compare graphs where the each node in $G_1$ maps on to a node in $G_2$ (**Known Node Correspondence**). For example we may be interested in different types of social interaction that occur between the same set of people, or how the flight patterns between the same set of airports changes over time or between different airlines. Secondly, we may be interested in comparing graphs where there isn't a precise mapping of nodes between the two graphs (**Unknown Node Correspondence**). For example if we wanted to know how similar are the commuting patterns between Boston and San Diego, or how the interaction structure of different protein complexes compares. Or we may be interested in comparing graphs of different sizes. There are different measures for tackling each of these problems. In general, measures for comparing graphs of unknown node correspondence can also be used for graphs with known node correspondence but not vice versa.\n",
    "\n",
    "Distance measures also differ in the types of graph they work on. Not all measures will work on directed or weighted graphs.\n",
    "\n",
    "In reality many graph distances are not true metrics because\n",
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13293fd0-5fa3-4b43-9ca3-c38cfba402fa",
   "metadata": {},
   "source": [
    "## Applications of graph distances\n",
    "1. Temporal anomaly detection:\n",
    "2. Graph classification and clustering:\n",
    "3. Similar nodes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef1ae41-84be-4eed-9632-84697403c5df",
   "metadata": {},
   "source": [
    "Types of distance measures:\n",
    "1. **Known node correspondence**\n",
    "    1. Matrix differences\n",
    "       1. Frobenius\n",
    "       2. Jaccard\n",
    "       3. Hamming\n",
    "       4. Canberra\n",
    "       5. Resistance perturbation?\n",
    "    3. DeltaCon\n",
    "    4. Cut distance\n",
    "2. **Unknown node correspondence**\n",
    "   1. Spectral distances\n",
    "   2. Global statistics\n",
    "   3. Mesoscopic response functions\n",
    "   4. Graphlet based methods\n",
    "   5. Alignment based methods\n",
    "   6. Portrait divergence\n",
    "   7. Graph kernels\n",
    "   8. Persistent homology\n",
    "   9. Bayesian methods\n",
    "   10. Jensen-Shannon divergence\n",
    "   11. Entropy divergence\n",
    "   12. NetSimile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88df35c2-0a31-4ed0-a891-304fb442519c",
   "metadata": {},
   "source": [
    "Important concepts\n",
    "1. Known vs unknown node correspondence\n",
    "2. Comparison within vs between graph ensembles\n",
    "3. Local vs meso vs macro structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ea385-7518-4a82-af49-be0f9020d58d",
   "metadata": {},
   "source": [
    "## 1. Frobenius norm\n",
    "- Idea that distances should have the property that isomorphic (or minimally edited graphs) ought to have a smaller distance\n",
    "- Compute $d$ for various instances of ER graph with different densities\n",
    "- Test sensitivity to removing, adding, switching or randomizing edges\n",
    "    - We expect distance to start at 0, and be a monotonically increasing function of perturbation. For randomization, distance should saturate as graph is fully randomized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1027a3-7292-495c-bd2e-bc6ab9e907ec",
   "metadata": {},
   "source": [
    "### What properties might a distance measure have?\n",
    "We can probably think of some properties that we might like a hypothetical distance measure to have. These are all arguable to some extent, but some such properties are\n",
    "1. **Sensitivity to perturbation**: If we perturb a graph $G$ slightly (eg adding/removing edges) resulting in $G'$ we might expect $D(G, G')$ to start off close to 0 and grow as the perturbation increases.\n",
    "\n",
    "2. **Irrelevance of random differences**: If we perturb a graph $G$ by randomizing edges resulting in $G'$, we might expect the distance $D(G, G')$ to asymptote as the graph becomes fully randomized.\n",
    "\n",
    "3. **Identity property**: the distance between the same graph (or two isomorphic graphs) should be 0 ie. $D(G_1, G_1) = 0$. Similarly, if $D(G_1,G_2) = 0$ then we might expect that $G_1 = G_2$.\n",
    "\n",
    "4. **Symmetry property**: we might expect that $D(G_1, G_2) = D(G_2, G_1)$\n",
    "\n",
    "5. **Zero property**: given $G$ and $\\overline{G}$ where $\\overline{G}$ contains all the edges which $G$ does not contain, we might expect that $D(G,\\overline{G})$ is maximal.\n",
    "\n",
    "6. **Within vs between family property**: We might expect that the average distance between graphs from different families should be greater than the distance between graphs of the same family. In other words, given two graphs that were generated from generative models $G(\\theta)$ and $F(\\omega)$ respectively, we expect that on average $D(G(\\theta), F(\\omega))$ should be greater than $D(G(\\theta), G(\\theta))$ or $D(F(\\omega), F(\\omega))$ for randomly drawn samples of $\\theta$ and $\\omega$. \n",
    "\n",
    "7. **The triangle inequality**: If we have three graphs $G_1$, $G_2$, $G_3$, we might expect that $D(G_1, G_3) \\leq D(G_1, G_2) + D(G_2, G_3)$. \n",
    "\n",
    "Any more? What do you think a good distance measure should do?\n",
    "\n",
    "Which of these seem most important to you when comparing graphs? Are there any that don't seem so important?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf1083-3ccc-41b5-8072-1cbef2fe4762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frobenius_norm_distance(g1, g2):\n",
    "    \"\"\"\n",
    "    Calculate the Frobenius distance between two graphs, g1 and g2.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c7ec7d-1f2a-48ae-8710-a5b7be050b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_graph(g, distance_function):\n",
    "    \"\"\"\n",
    "    Iteratively perturb graph g and compute distance between g and the perturbed graph at each step \n",
    "    using the distance measure distance_function. Two different perturbations are considered:\n",
    "    1. Removing edges\n",
    "    2. Adding edges\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3384f36-4100-4629-9111-bcb881e271c0",
   "metadata": {},
   "source": [
    "Is the Frobenius distance symmetric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf51a46-1afe-4ad1-a5f3-70a6b22ff519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "g1 = nx.watts_strogatz_graph(500, 9, 0.05)\n",
    "g2 = nx.watts_strogatz_graph(500, 9, 0.01)\n",
    "d = frobenius_norm_distance(g1, g2) \n",
    "print('$D(G_1, G_2) =$', d)\n",
    "d = frobenius_norm_distance(g2, g1) \n",
    "print('$D(G_2, G_1) =$', d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b97d07-4727-4a89-9706-6db149f7c48c",
   "metadata": {},
   "source": [
    "Does Frobenius distance obey the identity property?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d59743-a058-436f-91e8-e5d51fbc10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = nx.watts_strogatz_graph(500, 9, 0.05)\n",
    "g2 = g1.copy()\n",
    "d = frobenius_norm_distance(g1, g2) \n",
    "print('$D(G_1, G_1) =$', d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31ba41-135a-4fef-b390-8e5db03f47dc",
   "metadata": {},
   "source": [
    "Lets test the sensitivity to perturbation property for this distance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b574b9b-75aa-4171-b622-7ba18ee44a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Your turn!\n",
    "\n",
    "def perturb_graph():\n",
    "    # Write a function that takes as input a graph of your choice and randomly switches edges. \n",
    "    # Compute at each step the distance between the original and perturbed graphs and plot the results\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d634f4-67d0-483c-970d-72749b827313",
   "metadata": {},
   "source": [
    "## 2. DeltaCon \n",
    "\n",
    "### Why DeltaCon?\n",
    "- Matrix based measures such as Frobenius norm consider each edge equally. Removing 3 edges will have the same effect regardless of where in the graph they are removed from. DeltaCon measures graph similarity based on **node affinities** which are influenced by the structure of the graph. Therefore, adding or removing an edge which is more important structurally (eg. removing an edge which disconnects the graph) is given more importance in DeltaCon.\n",
    "- Robustness to noise: \n",
    "- Speed:\n",
    "\n",
    "### What is DeltaCon?\n",
    "$$s_{ij} = [I - \\epsilon^2 D - \\epsilon A]^{-1}$$\n",
    "$$ d = \\sqrt{\\sum_{i,j=1}^N \\sqrt{s_{ij}^1} - \\sqrt{s_{ij}^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85236711-7e96-4186-8c45-35a7eb6f8505",
   "metadata": {},
   "source": [
    "## 3. Spectral distances\n",
    "- \"Comparison using the first k eigenvalues  for small k allows one to focus on the community structure of the graph, while ignoring the local structure of the graph [15]. Inclusion of the highest-k eigenvalues  allows one to discern local features as well as global. This flexibility allows the user to target the particular scale at which she wishes to study the graph, and is a significant advantage of the spectral distances.\" (Wills 2020)\n",
    "- \"It is a well-known result that the multiplicity of the zero eigenvalue is the number of connected components of the graph, i.e. if , then there are precisely k connected components of the graph [22]. Furthermore, in such a case, the first k eigenvectors can be chosen to be the indicator functions of the components. There exists a relaxed version of this result: if the first k eigenvalues are very small (in a sense properly defined), then the graph can be strongly partitioned into k clusters (see [15] for the rigorous formulation of the result).\" (Wills 2020)\n",
    "- Maybe test using different numbers of eignevalues on different graphs to see the difference between macro and micro structure?\n",
    "\n",
    "$$ d = \\sqrt{\\sum_{i=1}^n (\\lambda_i^A - \\lambda_i^{A'})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62afaf9b-aaa5-4abc-8ffc-891911d9c97f",
   "metadata": {},
   "source": [
    "## 4. Portrait divergence/Graphlet based?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ad0e8-41c9-4c09-bb32-647db7767439",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "## References and further resources:\n",
    "\n",
    "1. Hartle, H., Klein, B., McCabe, S., Daniels, A., St-Onge, G., Murphy, C., Hébert-Dufresne, L., 2020. Network comparison and the within-ensemble graph distance. Proc. R. Soc. A. 476, 20190744. https://doi.org/10.1098/rspa.2019.0744\n",
    "2. Soundarajan, S., Eliassi-Rad, T., Gallagher, B., 2014. A Guide to Selecting a Network Similarity Method, in: Proceedings of the 2014 SIAM International Conference on Data Mining. Presented at the Proceedings of the 2014 SIAM International Conference on Data Mining, Society for Industrial and Applied Mathematics, pp. 1037–1045. https://doi.org/10.1137/1.9781611973440.118\n",
    "3. Tantardini, M., Ieva, F., Tajoli, L., Piccardi, C., 2019. Comparing methods for comparing networks. Sci Rep 9, 17557. https://doi.org/10.1038/s41598-019-53708-y\n",
    "4. Wills, P., Meyer, F.G., 2020. Metrics for graph comparison: A practitioner’s guide. PLoS ONE 15, e0228728. https://doi.org/10.1371/journal.pone.0228728\n",
    "5. Koutra, D., Vogelstein, J.T., Faloutsos, C., 2013. DeltaCon : A Principled Massive-Graph Similarity Function, in: Proceedings of the 2013 SIAM International Conference on Data Mining. Presented at the Proceedings of the 2013 SIAM International Conference on Data Mining, Society for Industrial and Applied Mathematics, pp. 162–170. https://doi.org/10.1137/1.9781611972832.18\n",
    "\n",
    "\n",
    "\n",
    "(Aim for 10+ useful citations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
